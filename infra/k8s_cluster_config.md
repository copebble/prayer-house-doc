# Kubernetes Cluster Config

ê°œì¸ ì„œë²„ on premise í™˜ê²½ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì„±
`kubeadm`ìœ¼ë¡œ êµ¬ì„±

> Debian ê³„ì—´ Linux í™˜ê²½ ê¸°ì¤€

- raspberry pi 4 (2ëŒ€)
- raspberry pi 5 (2ëŒ€)

(raspberry ê¸°ë³¸ ì„¤ì •ì€ ìƒëµ)

> All Nodes: í´ëŸ¬ìŠ¤í„°ì— ì°¸ì—¬í•˜ëŠ” ëª¨ë“  ë…¸ë“œë“¤ ëŒ€ìƒ(control-plane, worker ëª¨ë‘ í¬í•¨)
> Control Plane: only control plane ëŒ€ìƒ

<br>

## References

ì°¸ê³  ë§í¬ ë¨¼ì € ì²¨ë¶€ (í•´ë‹¹ ê¸€ ë³´ê³  ì§„í–‰í•´ë„ ë¬´ë°©)

- [k8s kubeadm ì§„í–‰ ë°©ë²• ê³µì‹ ë¬¸ì„œ](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
- [kubeadmìœ¼ë¡œ ì„¤ì¹˜í•´ë³´ê¸° (blog)](https://velog.io/@moonblue/kubeadm-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0)
- [raspberry pi kubeadm í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜ (blog)](https://velog.io/@2h-kim/RaspberryPI-Kubernetes-%EA%B5%AC%EC%B6%95)

<br>

## ğŸ“Œ ì„œë²„ ì»´í“¨í„° ì„¤ì • (All Nodes)

- swap off
- cgroup ì„¤ì •

### swap off

ì¿ ë² ë¡œ êµ¬ì„±í•  ëª¨ë“  ë…¸ë“œë“¤ì— ë©”ëª¨ë¦¬ Swap ë¹„í™œì„±í™” í•´ì•¼ í•œë‹¤.
memory swap í™œì„±í™”ì‹œ ê° ë…¸ë“œë³„ ì»¨í…Œì´ë„ˆ ì„±ëŠ¥ ì¼ê´€ì„±ì´ ê¹¨ì§ˆ ìˆ˜ ìˆì–´ì„œ ë¹„í™œì„±í™” ì²˜ë¦¬í•œë‹¤ê³  í•œë‹¤. 
(ì¿ ë²  í´ëŸ¬ìŠ¤í„°ì— ì°¸ì—¬í•˜ëŠ” ëª¨ë“  ë…¸ë“œë“¤ì€ ì¼ê´€ëœ ì„±ëŠ¥ì„ ê°€ì§€ê³  ìˆëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  í•œë‹¤.)

```shell
sudo dphys-swapfile swapoff
sudo dphys-swapfile uninstall
sudo update-rc.d dphys-swapfile remove
sudo apt purge dphys-swapfile -y

free -m

sudo systemctl reboot
```

### cgroup ì„¤ì •

raspberry piëŠ” ê¸°ë³¸ì ìœ¼ë¡œ cgroup ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•´ë‘ëŠ”ë° í•´ë‹¹ ì„¤ì •ì„ í™œì„±í™”í•´ì•¼ í•œë‹¤.
ì•ˆ ê·¸ëŸ¬ë©´ `kubeadm init` ìˆ˜í–‰í•˜ëŠ”ë° ìˆì–´ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê²ƒì´ë‹¤.

```shell
...
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: missing # ì˜¤ë¥˜
CGROUPS_PIDS: enabled
...
```

```shell
$ stat -fc %T /sys/fs/cgroup/
cgroup2fs
```
ë¨¼ì € ì‚¬ìš©í•˜ê³  ìˆëŠ” osì—ì„œ cgroup v1, v2ì¸ì§€ ì²´í¬í•„ìš”
v2 ì´ë©´ `systemd.unified_cgroup_hierarchy=1`ë¥¼ ì¶”ê°€í•˜ë©´ ëœë‹¤.
v1 ì´ë©´ `cgroup_memory=1 cgroup_enable=memory` ì´ê²ƒë§Œ ì‘ì„±

`cmdline.txt`ì— ìƒˆë¡­ê²Œ ë‚´ìš© ì¶”ê°€í•´ì•¼ í•œë‹¤.
```shell
sudo vim /boot/firmware/cmdline.txt

[...ê¸°ì¡´ ë‚´ìš©...] cgroup_memory=1 cgroup_enable=memory (systemd.unified_cgroup_hierarchy=1)
```

> ì£¼ì˜ í•  ì ì€ í•´ë‹¹ cmdline.txt íŒŒì¼ì€ ë°˜ë“œì‹œ í•œ ì¤„ë¡œ appendí•´ì„œ ì‘ì„±í•´ì•¼ í•œë‹¤.
> ìƒˆ ì¤„ë¡œ í•´ì„œ ì„¤ì •í–ˆë‹¤ê°€ bootingì´ ì•ˆë¼ì„œ ë‹¤ì‹œ osë¥¼ ì„¤ì¹˜í•´ì•¼ í•˜ëŠ” ë¶ˆìƒì‚¬ ë°œìƒí•  ìˆ˜ ìˆìŒ

<br>

## ğŸ“Œ ì„œë²„ ë‚´ k8s repository ì„¤ì • (All Nodes)

k8s v1.31

> ê³µì‹ë¬¸ì„œ ì°¸ê³ 
> https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

```shell
# k8s repository ì„¤ì •ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
sudo apt-get install -y apt-transport-https ca-certificates curl gpg

# k8s repositoryìš© public signing key ë‹¤ìš´ë¡œë“œ
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```
ìœ„ ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œì— ë‚˜ì™€ ìˆëŠ” ë‚´ìš©

<br>

## ğŸ“Œ Install kube command program (All Nodes)

k8s cluster êµ¬ì„±ì„ ìœ„í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì§„í–‰í•´ì•¼ í•¨

```shell
wget -qO- get.docker.com | sh
```
docker ì„¤ì¹˜ í•´ì•¼ í•¨

```shell
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```
k8s cluster êµ¬ì„±ì„ ìœ„í•œ kubeadm íŒ¨í‚¤ì§€ì™€ cluster êµ¬ì„± ë° ê´€ë¦¬ì— í•„ìˆ˜ì¸ kubelet, kubectl ì„¤ì¹˜

<br>

## ğŸ“Œ CRI êµ¬ì„± (All Nodes)

[Container Runtime Interface](https://kubernetes.io/ko/docs/concepts/architecture/cri/)

> You need a working container runtime on each Node in your cluster, so that the kubelet can launch Pods and their containers.

ëª¨ë“  ë…¸ë“œë“¤ì— CRI êµ¬ì„±ì´ í•„ìˆ˜ë‹¤. ê·¸ë˜ì•¼ kubeletì´ ê° ë…¸ë“œë“¤ì„ ì»¨íŠ¸ë¡¤ í•  ìˆ˜ ìˆëŠ” ê²ƒ ê°™ë‹¤.

```shell
# ì—†ëŠ” ê²½ìš°ì—ë§Œ
mkdir -p /etc/containerd
containerd config default > /etc/containerd/config.toml

# config.toml íŒŒì¼ì—ì„œ SystemdCgroup ì„¤ì •ê°’ í™•ì¸ ë° ë³€ê²½
# SystemdCgroup ê°’ì´ false ë¼ë©´ true ë¡œ ë³€ê²½í•´ì•¼ í•¨
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

# containerd.service ë³€ê²½ì‚¬í•­ ì ìš©
sudo systemctl restart containerd
```

<br>

## ğŸ“Œ Control Plane ì„¤ì • (Control Plane)

```shell
kubeadm init \
--apiserver-advertise-address={Control Plane ë™ì‘í•  ì„œë²„ ip}  \
--pod-network-cidr=192.168.0.0/16
```
- `pod-network-cidr`
  - ì»¨í…Œì´ë„ˆì˜ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­
  - `192.168.0.0/16`: í•´ë‹¹ ip ëŒ€ì—­ìœ¼ë¡œ í•œ ê²ƒì€ ì¡°ê¸ˆ ìˆë‹¤ê°€ ì„¤ì¹˜í•  calicoì˜ default ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì´ê¸° ë•Œë¬¸. ë‹¤ë¥¸ ê±¸ë¡œ í•´ë„ ìƒê´€ ì—†ë‹¤.

```
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

sudo kubeadm join [server_url]:6443 --token [...] \
	--discovery-token-ca-cert-hash sha256:[...]
```
ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ë©´ ìœ„ì™€ ê°™ì€ ë©”ì‹œì§€ê°€ ë‚˜ì˜¤ëŠ”ë° ê·¸ëŒ€ë¡œ í•˜ë©´ ëœë‹¤.

```shell
sudo kubeadm join [server_url]:6443 --token [...] \
	--discovery-token-ca-cert-hash sha256:[...]
```
ê·¸ë¦¬ê³  ê° worker nodeì— ìœ„ ëª…ë ¹ì–´ ì…ë ¥í•˜ë©´ ëœë‹¤.

<br>

## ğŸ“Œ Calico ì„¤ì¹˜ (Control Plane)

ê° worker nodeì— joinê¹Œì§€ ì™„ë£Œë˜ì—ˆë‹¤ë©´ control plane ì„œë²„ì—ì„œ `kubectl get pods` í•´ë³´ë©´ ê° nodeê°€ NotReadyë¡œ ë‚˜ì˜¬ ê²ƒì´ë‹¤.

ì¶”ê°€ë¡œ í”ŒëŸ¬ê·¸ì¸ì„ ì ìš©í•´ì•¼ í•˜ëŠ”ë° ë‹¤ìŒ ê³¼ì • ì§„í–‰í•˜ë©´ ëœë‹¤.

ì¿ ë²  ì»¨í…Œì´ë„ˆ ê°„ í†µì‹ ì„ ìœ„í•œ í”ŒëŸ¬ê·¸ì¸ 3ê°œ ì¤‘ í•˜ë‚˜

- ê³µì‹ ë¬¸ì„œ ì°¸ê³ 
    https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart

í•´ë‹¹ í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ ê° ë…¸ë“œ ê°„ì— ì„œë¡œ í†µì‹ ì´ ê°€ëŠ¥í•œ ìƒíƒœê°€ ëœë‹¤.

```shell
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/tigera-operator.yaml
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/custom-resources.yaml
```
ê°„ë‹¨í•˜ê²Œ ì„¤ì¹˜ ê°€ëŠ¥

<br> 

## ğŸ“Œ Nginx Ingress Controller ì„¤ì¹˜

ì™¸ë¶€ì— í´ëŸ¬ìŠ¤í„° ë‚´ìš©ì„ ì˜¤í”ˆí•´ì•¼í•  ë•Œ ì—¬ëŸ¬ ê°ì²´ë“¤ì„ ì‚¬ìš©í• í…ë° ê·¸ ì¤‘ `Ingress` ê°ì²´ë¥¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê²ƒ ê°™ë‹¤. 
IngressëŠ” routing ëª…ì„¸ì„œ ê°™ì€ ë‹¨ìˆœ ë¬¸ì„œì´ê³  ì´ê±¸ ê°€ì§€ê³  ì‹¤ì œ ë™ì‘í•˜ëŠ” ê²ƒì€ ingress controllerì—ì„œ í•˜ê²Œ ëœë‹¤.

Ingressë¥¼ ì‚¬ìš©í• ê±°ë©´ Ingress Controllerë¥¼ í•„íˆ ì„¤ì¹˜í•´ì•¼ í•œë‹¤. 
ê·¸ ì¤‘ ë³´í¸ì ìœ¼ë¡œ ì“°ì´ëŠ” Nginx Ingress Controller ì„ íƒ

([ê³µì‹ document ì„¤ì¹˜ ê°€ì´ë“œ](https://kubernetes.github.io/ingress-nginx/deploy/))

```shell
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.11.2/deploy/static/provider/cloud/deploy.yaml
```
ê°„ë‹¨í•˜ê²Œ apply yamlë¡œ ì„¤ì •(ì •ë§ ê°„ë‹¨)
ê·¸ë¦¬ê³  ê³µì‹ ë¬¸ì„œì—ì„œ ê°€ì´ë“œí•´ì£¼ëŠ”ëŒ€ë¡œ Local test í•´ë³¼ ê²ƒì„ ì¶”ì²œ

<br> 

## ğŸ“Œ Credential ë“±ë¡

ì‘ì„±í•  ê²ƒ

<br> 

## ğŸ“Œ Context ë“±ë¡

ì‘ì„±í•  ê²ƒ